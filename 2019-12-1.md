**姓名** 仇鑫

**日期** 2019/11/25 - 2019/12/1

------

### 本周已完成任务

1. 阅读论文《Improving the Explainability of Neural Sentiment Classifiers via Data Augmentation 》
2. 参加外教课

### 总结

《Improving the Explainability of Neural Sentiment Classifiers via Data Augmentation 》认为，广泛适用的本地解释方法LIME可以识别一组关键字作为解释，但对同一个句子将LIME应用在不同的情感分类器上，得到的结果是不同的，即使两个情感分类器都做出了正确的预测。如下图所示，A的效果远不如B的效果，虽然A、B都将该评论的情感预测为积极的，但对人而言，B得到解释更好解释模型。



在实践中真正的挑战是解释是否易于理解。通过关注解释及其解释性之间的联系和差异，试图研究关于提高情感分类器的解释性的问题。使用数据增强来提高神经情感分类器的可解释性。 论文提出了两种数据增强方法：一种将预定义的情感词汇表作为外部知识，另一种使用对抗样本。



第一种方法是创建一些与训练示例有关的表面形式类似的示例，但是这些示例不属于任何预定义的标签，具体而言，用于情感分析的增强样例是与原始训练示例相似但没有情感标签的样例。用到的方法就是对于一个给定的句子，删除一些句子里的词，这些词是在预设的词典里的。对于一些简单的文本，删除情感词将导致它们成为不完整的句子，仍然可以用作扩充数据点。例如，如果我们删除“I like this movie ”中的情感词，则增强训练样例就是“I this movie ”。事实上，这些增强样例可以帮助模型更加突出情感预测。



第二种方法则是通过对抗样本。具体而言，此方法旨在最大程度地减少原始示例与对抗示例之间的修饰词数量，并通过仅替换几个同义词来保持语义和句法相似性。在每一生成中，通过替换同义词生成一组候选示例，然后由Google十亿单词语言模型选择最适合上下文的那些示例。由于对抗性示例可以改变模型预测，因此原始文本中被替换的单词对于情绪预测非常重要。



在最终的评判中，使用了两种方法，一种是人进行评判，另一种是提出了相关得分这一评判指标。相关得分是相关样例数与实例总数之比。

对于给定的测试示例，取决于模型所预测的情感极性（由解释和实际情况指示），如果满足以下两个条件之一，则将被视为一致情况：

条件1：如果解释所指示的情感极性不为空并且与模型预测一致；

条件2：如果解释所指示的情感极性为空，并且模型预测与真实情况不同。

