**姓名** 仇鑫

**日期** 2019/10/7 - 2019/10/13

------

### 本周已完成任务

2. 对情感分析任务进行重构
2. 查阅最近可解释性论文的动向

### 总结

进行了一些调参，以下为CNN的精确度

Dev average Loss: 2.360665  Dev accuracy: 0.798165

Test average Loss: 1.949252  Test accuracy: 0.796266

使用原始的GBDT精确度目前只能达到 0.6705107084019769，差距仍然较大，可能原因是因为CNN本来就不够精确，导致GBDT很难训练精确。目前准备先实现计算重要性的部分，看看效果如何。

关于实验结果的思考，Anchors论文里并没有NLP任务的精度，可能以样例展示更适合作为结果的表现，这里无法得到数值进度，我做了一些思考。NLP任务因为使用了Embedding，其特征的维度很大，且测试数据集中不一定能存在验证集上得出的规则，这就导致准确度的数值会很低。举个例子，一句话可能由各种各样的词构成，可能测试集出现的词，验证集中没有。这和Tabular数据集不同，Tabular数据集对应的特征是固定的，如age和gender在验证集测试集都有出现，如果验证集中认为age更重要，在测试集中很容易去利用age这个特征。