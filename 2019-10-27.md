**姓名** 仇鑫

**日期** 2019/10/21 - 2019/10/27

------

### 本周已完成任务

2. 修改知识蒸馏之前的模型
2. 思考评价方法

### 总结

通过修改知识蒸馏之前的模型，将CNN换成的Attention+LSTM，模型结构如下图，



Attention是加在LSTM之后，使用Self-Attention，这里参考了《A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING 》这篇论文的结构。



这样蒸馏之前的模型在测试集上的精度从78%提高到了88%，这时候再进行知识蒸馏，简单的调参，得到了 74.3%的准确度（没有使用初始化树），使用初始化树的准确度为 72.3%。

后面正在思考如何应用LIME或者Anchor进行比较。