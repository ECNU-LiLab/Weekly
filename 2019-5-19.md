**姓名** 仇鑫

**日期** 2019/5/13 - 2019/5/19

------

### 本周已完成任务

1. 模型调参
2. 从GBDT中提取出交叉特征，之后使用LR
3. 阅读《HIERARCHICAL INTERPRETATIONS FOR NEURAL NETWORK PREDICTIONS》

### 下周计划

3. 阅读《Tree-enhanced Embedding Model for Explainable Recommendation》

### 总结

使用GBDT获取教师网络的组合特征，将特征经过one-hot编码作为新的特征输入到LR模型训练。同时新的特征也是用普通的CART树进行对比。

这里使用的模型是20000的数据集，X_train shape:  (18000, 1, 61, 300)，因为这里GBDT是多分类问题，使用这里是通过两个GBDT模型来实现多分类，将每个模型的组合特征提取出来，构建的新的输入为 train_new_feature shape:  (18000, 200)

决策树的准确度为 66.6%

原GBDT的准确度为84.25%

GBDT+LR的准确度为84.45%

可以发现，增加LR的效果要比增加CART要好很多，甚至增加LR的模型要比原来只用GBDT的效果更好。之后尝试使用40000的数据集进行测试。