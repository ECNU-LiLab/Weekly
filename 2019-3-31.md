**姓名** 仇鑫

**日期** 2019/3/25 - 2019/3/31

---

### 本周已完成任务

1. 调试运行emnlp2018的源码
2. 阅读 logicnn，准备修改代码
3. 阅读Python自然语言处理
4. 尝试弄懂《Improving the Interpretability of Deep Neural Networks with Knowledge Distillation》相关细节问题

### 下周计划

1. 阅读 logicnn，修改代码
2. 阅读Python自然语言处理
3. 阅读《Harnessing Deep Neural Networks with Logic Rules》和源码，思考教师网络和学生网络是如何相互影响
4. 思考将《Improving the Interpretability of Deep Neural Networks with Knowledge Distillation》中的多分类决策树变成迭代的更新过程
5. 将 《Harnessing Deep Neural Networks with Logic Rules》的主要公式整理出来，考虑如何修改公式将学生网络替换成决策树
6. 阅读《[Hierarchical interpretations for neural network predictions](https://openreview.net/pdf?id=SkEqro0ctQ)》

### 总结

简单扫了眼《Distilling Knowledge from Deep Networks with
Applications to Healthcare Domain》和 《Interpretable Deep Models for ICU Outcome Prediction》，但其操作都是讲teacher网络训练好才能够蒸馏出student网络，并没做到同步迭代的做法。

在分析 logicnn 是如何运作的时候，发现其主要是对[CNN_sentence](https://github.com/yoonkim/CNN_sentence)，也就是对[《Convolutional Neural Networks for Sentence Classification》](http://arxiv.org/pdf/1408.5882v2.pdf)这篇论文的模型，做了迭代的知识蒸馏操作。

![屏幕快照 2019-03-31 下午6.50.02](/Users/qiuxin/Desktop/屏幕快照 2019-03-31 下午6.50.02.png)

事实上，LogicNN用到的network是之前定义好的MLPDropout，教师网络和学生网络的区别就在于

![屏幕快照 2019-03-31 下午7.37.54](/Users/qiuxin/Desktop/屏幕快照 2019-03-31 下午7.37.54.png)

p 为学生网络，q为教师网络，可以看出，这一步实际上就是将学生网络投射到教师网络，calc_rule_constraints就是嵌入逻辑规则。



关于决策树的选择，通过比对发现，使用GBDT梯度提升树相对更加适合，GBDT中的树都是回归树，不是分类树，为了做到迭代训练决策树，可以引入Online Learning的思想，Online learning， 他的数据是come in sequence，也就是说traning sample 是一个一个来，或则是几个几个来，然后classifer 根据新来的samples进行更新。

另外，发现了一篇相对有用的论文[Hierarchical interpretations for neural network predictions](https://openreview.net/pdf?id=SkEqro0ctQ)，使用这种层次解释树作为知识蒸馏出来的结果或许是一个可以考虑的切入点。

![intro](/Users/qiuxin/Desktop/intro.png)