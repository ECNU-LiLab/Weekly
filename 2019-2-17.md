**姓名** 仇鑫

**日期** 2019/2/4 - 2019/2/17

---

### 本周已完成任务

1. 阅读 << Harnessing Deep Neural Networks with Logic Rules >>
2. 调试 Natural Language Toolkit
3. 测试 word2vec
4. 阅读 << Visualizing Higher-Layer Features of a Deep Network >>
5. 正在写可解释性的综述

### 下周计划

1. 完成可解释性的综述
2. 阅读<<[Distributed Representations of Words and Phrases and their Compositionality](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)>>

### 总结

春节期间发热感冒导致进度缓慢，之后会慢慢补上。

Harnessing Deep Neural Networks with Logic Rules 提出了将结构化逻辑规则引入深度神经网络来提高可解释性，本文提出了一种方法将逻辑规则信息整合到神经网络的权重中。其开发了一个组合一阶逻辑规则到深度神经网络的框架，使用迭代蒸馏的方法，这种转化是通过使用了后正则化原理的教师网络来构建的。这里一阶逻辑规则利用了软逻辑公式，可以轻松扩展到通用概率模型。



Visualizing Higher-Layer Features of a Deep Network 本文想找出深度模型所提取到的高级特征的比较好的定性解释。通过在几个视觉数据库中训练堆叠降噪自动编码器和DBN深信网络，并比较几种不同的高级特征可视化的方法。虽然这些特征的显示是在单元级别上面的，也许有违于直观理解，但它很容易实现，而且在不同方法上面得到的结果也是一致的。本文中，介绍三种可视化的方法：激活最大化、采样和线性组合法。

##### 激活最大化

寻找使一个给定的隐层单元的激活值最大的输入模式。因为第一层的每一个节点的激活函数都是输入的线性函数，所以对第一层来说，它的输入模式和滤波器本身是成比例的。

##### 采样

通过块Gibbs采样方法对DBN的两层进行采样。

##### 线性组合

Lee等（2008）在他们的论文中展示了一种可视化第二层隐层的节点的特征的方法。他们是基于一个神经元节点可以由和其强连接的上一层的滤波器的组合来描述的假设的。该层的某个节点的可视化可以通过上一层滤波器的线性加权得到，每个滤波器的权值就是该滤波器与这个节点之间的连接权值。

他们用自然图像训练了一个具有激活值稀疏约束的DBNs，然后用这种方法显示它在第二层学习到的是一个角的检测器。Lee拓展了这个方法去可视化第三层学习到的东西：通过简单对第二层的滤波器进行加权，权值是第二层滤波器到第三层该节点的连接权值，而且选择的是最大的那个权值。

