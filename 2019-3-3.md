**姓名** 仇鑫

**日期** 2019/2/25 - 2019/3/3

---

### 本周已完成任务

1. 准备论文的报告
2. 完成 CS224N Assignment 1
3. 阅读  Geoffrey Hinton, Oriol Vinyals, Jeff Dean << Distilling the Knowledge in a Neural Network >>

### 下周计划

1. 继续搜集可解释性相关论文
2. 阅读  Geoffrey Hinton, Oriol Vinyals, Jeff Dean << Distilling the Knowledge in a Neural Network >>

### 总结

#####可解释性 综述框架

Introduction

介绍可解释性的定义，以及为什么需要可解释性。

Related work

多角度介绍前沿的相关研究，从两个方面考虑，模型的透明度和模型的功能性。

模型的透明度即将黑箱模型打开，从而做到部分可解释性。

模型的功能性即解释模型判断的相关依据。

Future work and Conclusion

讨论可解释性研究的相关难点，展望未来应该做到的一些方向



#####知识蒸馏

核心思想是通过迁移知识，从而通过训练好的大模型得到更加适合推理的小模型。重点idea就是提出用soft target来辅助hard target一起训练，而soft target来自于大模型的预测输出。hard target 包含的信息量（信息熵）很低，soft target包含的信息量大，拥有不同类之间关系的信息。

算法步骤

1. 训练大模型：先用hard target，也就是正常的label训练大模型。

2. 计算soft target：利用训练好的大模型来计算soft target。也就是大模型“软化后”再经过softmax的output。

3. 训练小模型，在小模型的基础上再加一个额外的soft target的loss function，通过lambda来调节两个loss functions的比重。

4. 预测时，将训练好的小模型按常规方式使用。

