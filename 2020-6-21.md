**姓名** 仇鑫

**日期** 2020/6/15 - 2020/6/21

------

### 本周已完成任务

1. 思考论文改进方案
2. 修改专利文档
3. 阅读《InfoGAN》
4. 华为船运到达时间预测

### 下周任务

1. 探索xgboost的可解释可行性
2. 学习GAN的相关知识

### 总结

关于使用GAN来做可解释性，这周只搜到一篇论文《[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets)》，通过非监督学习得到可分解的特征表示。使用GAN加上最大化生成的图片和输入编码之间的互信息。最大的好处就是可以不需要监督学习，而且不需要大量额外的计算花销就能得到可解释的特征。前人也通过很多监督非监督的方法学习可分解的特征。在这篇paper中，非监督学习通过使用连续的和离散的隐含因子来学习可分解的特征。这里的可解释性有点类似之前我做的论文报告，利用互信息进行NLP的可解释。对于GAN，实际上它的目标其实是得到一个与real data分布一致的fake data分布。但是由于generator的输入是一个连续的噪声信号，并且没有任何约束，导致GAN将z的具体维度与output的语义特征对应起来，可解释性很差。InfoGAN的原理就是在info GAN里面，把输入向量z分成两部分，c和z'。c可以理解为可解释的隐变量，而z可以理解为不可压缩的噪声。希望通过约束c与output的关系，使得c的维度对应output的语义特征，以手写数字为例，比如笔画粗细，倾斜度等。为了引入c，坐着通过互信息的方式来对c进行约束，也可以理解成自编码的过程。具体的操作是，generator的output，经过一个分类器，看是否能够得到c。其实可以看成一个auto-encoder的反过程。其余的discriminator与常规的GAN是一样的。因为对GAN的内容有点生疏，所以网络结构不太熟悉，准备看一下相关的内容再回来看实验。

