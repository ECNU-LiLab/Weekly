**姓名** 仇鑫

**日期** 2019/3/11 - 2019/3/17

---

### 本周已完成任务

1. 阅读 《Revisiting the Importance of Encoding Logic Rules in Sentiment Classification》
2. 阅读《深度学习》第四章
3. 阅读logicnn源码寻找切入点
4. 阅读《A 2-phase Frame-based Knowledge Extraction Framework》
5. 阅读《深度学习的可解释性》
6. 搜集知识蒸馏与可解释性相结合的论文

### 下周计划

1. 思考领域知识与知识蒸馏相结合
2. 搜集知识蒸馏与可解释性相结合的论文
3. 阅读《Interpreting Blackbox Models via Model Extraction》
4. 阅读《Learning Interpretable Models with Causal Guarantees》

### 总结

《Revisiting the Importance of Encoding Logic Rules in Sentiment Classification》是对之前ACL16的论文进行了研究和探讨，该论文认为后者引入*A-but-B* 实际上并没有足够的好，实际上上下文词嵌入就可以做到比引入逻辑更好的效果。首先ACL16论文的难点在于教师网络的构建，也就是如何将学生网络投影到教师网络，这里参考了《[Posterior Regularization for Structured Latent Variable Models](http://www.jmlr.org/papers/volume11/ganchev10a/ganchev10a.pdf)》，此外迭代更新参数的方式在上述提到的论文里也有介绍。通过重现实验发现，ACL16的性能主要是源于投影而不是知识蒸馏，并且还与随机种子有关。通过对比试验，论文认为ELMo嵌入可以学习 *A-but-B*的结构。



《A 2-phase Frame-based Knowledge Extraction Framework》提出了一种从自然语言文本中提取知识的方法，第一步是将标准的NLP任务整合成知识图谱的RDF图结构，第二步是根据语义构建出知识图谱。首先通过linguistic feature extraction对多个NLP任务进行提取文本的语言结构表达，从而构建出mention。之后就是对知识图谱进行知识蒸馏。通过创建映射规则来从Mention层进行提取，将结果构建成实例层。本文提出了PIKES，一种从文本中提取面向框架的知识的方法，该方法将处理分为两个阶段（语言特征提取和知识分离），通过中间RDF mention图解耦。 PIKES去耦提供了几个好处：（i）轻松更换NLP工具; （ii）在知识分离期间容易（基于规则）组合不同NLP任务的输出，以支持非平凡的语言现象（例如，论证名词化）; （iii）单一RDF模型，能够表示各个层面（资源，mention，实例）涉及的所有信息以及每个提取知识的起源跟踪。



