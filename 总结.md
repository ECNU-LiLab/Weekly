**姓名** 仇鑫



###总结

对于新提出的公式做了相应的对比试验，效果并没有提高，同时把相应的实验进行完善补全，并填写到论文里。

另一部分主要在做针对可解释性的探索，从两个方面进行研究。

1. 利用对抗样本来研究模型可解释性，以论文《Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency》的相关实验为主，本论文提出使用基于概率权重的词显著性来产生对于的对抗样本，通过修改词主要为同义词，利用这种方法可以发现模型对于哪些词会比较敏感，这个我觉得也就是模型的解释性。
2. 利用梯度来研究模型的可解释性，以论文《Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization》，输入向量经过神经网络进行前向传播，计算出此时的loss，对loss进行反向传播，这时候收集loss对于输入特征的梯度，这个梯度就可以代表处输入的特征对于模型最终的输出结果的贡献程度。

另外考虑到SST2数据集在可解释性上效果没有很显著，正在进行尝试使用IMDB影评数据集进行简单的测试。

