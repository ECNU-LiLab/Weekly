**姓名** 仇鑫

**日期** 2020/4/27 - 2020/5/3

------

### 本周已完成任务

1. 修改润色专利
2. 阅读论文《Towards a Deep and Unified Understanding of Deep Neural Models in NLP》

### 下周任务

1. 研读可解释性方向新的论文
2. 报名华为的比赛



### 总结

《Towards a Deep and Unified Understanding of Deep Neural Models in NLP》本文通过定义一个基于信息的统一度量，以提供有关NLP模型的中间层是如果利用输入单词进行预测的解释。本文旨在基于满足一致性和通用性的方法提供定量的解释。一致性对应于公平性的概念，它要求度量标准量化输入和潜在表示之间的关联，而对特定形式的关系没有偏差。本文研究了已下三个问题：

1. 如何使用互信息定量解释DNN的中间层
2. 能否利用基于信息的度量作为工具来从理论上分析和比较现有的解释方法
3. 如何基于信息的衡量方法丰富DNN的可解释能力并提供解释

本文定义了一个基于信息的统一度量，以量化在深度NLP模型的中间层中编码了一个输入单词的信息的数量。我们证明了我们的度量在一致性和通用性方面领先于现有度量。 可以通过基于扰动的近似有效地估计此度量，并且可以将其用于单词属性的细粒度分析。

本文展示了如何将基于信息的度量用作比较不同解释方法的工具，并证明该方法可以看作是最大熵优化和最大似然估计的组合。

通过在一个人工数据集和三个真实基准数据集中进行实验，演示了基于信息的度量如何丰富了解释DNN的能力。