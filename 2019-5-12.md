**姓名** 仇鑫

**日期** 2019/4/22 - 2019/5/12

------

### 本周已完成任务

1. 修改模型的输入，换成词向量
2. 理解数据集的构建
3. 阅读《Python自然语言处理》
4. 阅读《HIERARCHICAL INTERPRETATIONS FOR NEURAL NETWORK PREDICTIONS》

### 下周计划

1. 阅读《Python自然语言处理》
2. 阅读《HIERARCHICAL INTERPRETATIONS FOR NEURAL NETWORK PREDICTIONS》
3. 阅读《Tree-enhanced Embedding Model for Explainable Recommendation》

### 总结

本周发现了之前模型一直没有效率的主要原因，并没有使用词向量来就进行训练，通过修改，在生成出简单的CART决策树，通过标记判断的词，可以简单的看出决策树的决策过程，此时CART的准确度大概在70%。

decision id node 0 : (X_test[a: 1243] (= 0.17592119) > -0.11617223918437958)
decision id node 348 : (X_test[very: 1543] (= 0.21376775) > -0.04016654193401337)
decision id node 846 : (X_test[rainy: 1899] (= 0.09779323) > 0.014534289482980967)
decision id node 1378 : (X_test[rainy: 2074] (= 0.09545004) > -0.053127916529774666)
decision id node 1464 : (X_test[day: 2283] (= 0.044554226) <= 0.0680479072034359)
decision id node 1465 : (X_test[rainy: 1842] (= 0.5234206) > 0.31950312852859497)
decision id node 1619 : (X_test[rainy: 1856] (= -0.358873) <= 0.05693688988685608)
decision id node 1620 : (X_test[rainy: 1810] (= 0.23178968) > 0.05053635500371456)
leaf node 1628 reached, no decision here
[0]

本周末尝试使用 $y_{hard}+\alpha y_{soft}$ 进行训练GBDT，训练集为9000， 测试集为1000，参数还未调整，教师网络只训练一个epoch的情况下，准确度已经达到了80%。

