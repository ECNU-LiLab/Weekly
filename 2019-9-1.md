**姓名** 仇鑫

**日期** 2019/8/26 - 2019/9/1

------

### 本周已完成任务

1. 理解anchors的实验部分
2. 尝试修改GBDT初始化

### 下周计划

1. 修改GBDT的初始化
2. 思考评价指标



### 总结

![屏幕快照 2019-09-01 上午9.08.59](/Users/qiuxin/Desktop/屏幕快照 2019-09-01 上午9.08.59.png)

![屏幕快照 2019-09-01 上午9.09.11](/Users/qiuxin/Desktop/屏幕快照 2019-09-01 上午9.09.11.png)

根据文档说明，在初始化GBDT的时候，实际上这里是用到了默认的判别器，所以尝试了将初始化参数用一颗决策树。

![屏幕快照 2019-09-01 下午2.58.08](/Users/qiuxin/Desktop/屏幕快照 2019-09-01 下午2.58.08.png)

![屏幕快照 2019-09-01 下午2.59.23](/Users/qiuxin/Desktop/屏幕快照 2019-09-01 下午2.59.23.png)

可以发现是GBDT在fit的时候出现了问题，目前思路是尝试给DecisionTreeRegressor添加上predict_proba的方法。



关于之前提到的submodular pick，可以理解为从解释矩阵中，挑选出最重要的不重叠的特征。

![屏幕快照 2019-09-01 下午5.41.03](/Users/qiuxin/Desktop/屏幕快照 2019-09-01 下午5.41.03.png)

上图是一堆实例构成的解释矩阵，f1,f2,f3为特征，每一行都是一个实例，选取尽可能覆盖重要特征的实例作为解释，比如选择了第二行，其重要特征为f2,f3，所以第三行就没必要选择，最后两行出现了新的特征f4,f5，submodular pick模型优先选择第五行，因为其两个重要特征都没在第二个实例中出现，关于找出全部的正解实际上是个NP难的问题，submodular pick提出的是利用贪心算法求出近似解。